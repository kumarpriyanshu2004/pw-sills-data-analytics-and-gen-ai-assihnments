{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SZxHtOhnwqB",
        "outputId": "7291b268-d571-40b4-ede9-bfd5f0579c51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy: 0.885\n"
          ]
        }
      ],
      "source": [
        "#21. Train a Bagging Classifier using Decision Trees on a sample dataset and print model accuracy.\n",
        "\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "# Generate a sample dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=42)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a Bagging Classifier with Decision Trees as base estimators\n",
        "bagging_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=100, max_samples=0.5, max_features=0.5, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "bagging_clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = bagging_clf.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model accuracy: {accuracy}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#22. Train a Bagging Regressor using Decision Trees and evaluate using Mean Squared Error (MSE).\n",
        "\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.datasets import make_regression\n",
        "\n",
        "# Generate a sample regression dataset\n",
        "X, y = make_regression(n_samples=1000, n_features=20, n_informative=15, noise=0.1, random_state=42)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a Bagging Regressor with Decision Trees as base estimators\n",
        "bagging_reg = BaggingRegressor(DecisionTreeRegressor(), n_estimators=100, max_samples=0.5, max_features=0.5, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "bagging_reg.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = bagging_reg.predict(X_test)\n",
        "\n",
        "# Evaluate the model using Mean Squared Error\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f\"Mean Squared Error: {mse}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKuorXxIoJ-c",
        "outputId": "0d9fc749-007a-4edb-e37b-cbca88522a2e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 20859.18631334302\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#23. Train a Random Forest Classifier on the Breast Cancer dataset and print feature importance scores.\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train a Random Forest Classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Print feature importances\n",
        "feature_importances = rf_classifier.feature_importances_\n",
        "for i, importance in enumerate(feature_importances):\n",
        "    print(f\"Feature {i}: {importance}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rv78LaddodMa",
        "outputId": "78e53aab-1113-494f-c041-a0cb865d264b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature 0: 0.048703371737755234\n",
            "Feature 1: 0.013590877656998469\n",
            "Feature 2: 0.053269746128179675\n",
            "Feature 3: 0.04755500886018552\n",
            "Feature 4: 0.007285327830663239\n",
            "Feature 5: 0.013944325074050485\n",
            "Feature 6: 0.06800084191430111\n",
            "Feature 7: 0.10620998844591638\n",
            "Feature 8: 0.003770291819290666\n",
            "Feature 9: 0.0038857721093275\n",
            "Feature 10: 0.02013891719419153\n",
            "Feature 11: 0.004723988073894702\n",
            "Feature 12: 0.01130301388178435\n",
            "Feature 13: 0.022406960160458473\n",
            "Feature 14: 0.004270910110504497\n",
            "Feature 15: 0.005253215538990106\n",
            "Feature 16: 0.009385832251596627\n",
            "Feature 17: 0.003513255105598506\n",
            "Feature 18: 0.004018418617722808\n",
            "Feature 19: 0.00532145634222884\n",
            "Feature 20: 0.07798687515738047\n",
            "Feature 21: 0.021749011006763207\n",
            "Feature 22: 0.06711483267839194\n",
            "Feature 23: 0.15389236463205394\n",
            "Feature 24: 0.010644205147280952\n",
            "Feature 25: 0.020266035899623565\n",
            "Feature 26: 0.031801595740040434\n",
            "Feature 27: 0.14466326620735528\n",
            "Feature 28: 0.010120176131974357\n",
            "Feature 29: 0.005210118545497296\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#24. Train a Random Forest Regressor and compare its performance with a single Decision Tree.\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.datasets import make_regression\n",
        "\n",
        "# Generate a sample regression dataset\n",
        "X, y = make_regression(n_samples=1000, n_features=20, n_informative=15, noise=0.1, random_state=42)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Random Forest Regressor\n",
        "rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_regressor.fit(X_train, y_train)\n",
        "rf_y_pred = rf_regressor.predict(X_test)\n",
        "rf_mse = mean_squared_error(y_test, rf_y_pred)\n",
        "print(f\"Random Forest Regressor Mean Squared Error: {rf_mse}\")\n",
        "\n",
        "# Train a single Decision Tree Regressor\n",
        "dt_regressor = DecisionTreeRegressor(random_state=42)\n",
        "dt_regressor.fit(X_train, y_train)\n",
        "dt_y_pred = dt_regressor.predict(X_test)\n",
        "dt_mse = mean_squared_error(y_test, dt_y_pred)\n",
        "print(f\"Decision Tree Regressor Mean Squared Error: {dt_mse}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0RAdt1So3ER",
        "outputId": "f6c71705-dcc9-40bd-91f6-bd00c9c6a587"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Regressor Mean Squared Error: 15965.304970831752\n",
            "Decision Tree Regressor Mean Squared Error: 36143.34306676809\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#25. Compute the Out-of-Bag (OOB) Score for a Random Forest Classifier.\n",
        "\n",
        "# Load the Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train a Random Forest Classifier with OOB scoring\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42, oob_score=True)\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Print the OOB score\n",
        "oob_score = rf_classifier.oob_score_\n",
        "print(f\"Out-of-Bag Score: {oob_score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gj1hRP74pCBP",
        "outputId": "59b9367a-aa50-4a31-b3a2-cac3f91d8f36"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Out-of-Bag Score: 0.9560439560439561\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#26. Train a Bagging Classifier using SVM as a base estimator and print accuracy.\n",
        "\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Create a Bagging Classifier with SVM as base estimators\n",
        "bagging_svm = BaggingClassifier(SVC(), n_estimators=10, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "bagging_svm.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = bagging_svm.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Bagging SVM accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbj1dSK4pKiW",
        "outputId": "3a4411ba-8c2a-40df-f598-f2e42f2b33b7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging SVM accuracy: 0.9473684210526315\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#27. Train a Random Forest Classifier with different numbers of trees and compare accuracy.\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "# Load the Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Number of trees to try\n",
        "n_estimators_list = [50, 100, 200]\n",
        "\n",
        "for n_estimators in n_estimators_list:\n",
        "    # Initialize and train a Random Forest Classifier\n",
        "    rf_classifier = RandomForestClassifier(n_estimators=n_estimators, random_state=42)\n",
        "    rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = rf_classifier.predict(X_test)\n",
        "\n",
        "    # Evaluate accuracy\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Accuracy with {n_estimators} trees: {accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Ol7uOYvpTIV",
        "outputId": "55552867-acfd-4d3b-dbd4-ef404303839d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with 50 trees: 0.9649122807017544\n",
            "Accuracy with 100 trees: 0.9649122807017544\n",
            "Accuracy with 200 trees: 0.9649122807017544\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#28. Train a Bagging Classifier using Logistic Regression as a base estimator and print AUC score.\n",
        "\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "# Generate a sample dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=42)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a Bagging Classifier with Logistic Regression as base estimators\n",
        "bagging_clf = BaggingClassifier(LogisticRegression(), n_estimators=100, max_samples=0.5, max_features=0.5, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "bagging_clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_proba = bagging_clf.predict_proba(X_test)[:, 1] #probability of positive class\n",
        "\n",
        "# Evaluate the model using AUC\n",
        "auc = roc_auc_score(y_test, y_pred_proba)\n",
        "print(f\"AUC score: {auc}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uRvSCqBpiTc",
        "outputId": "23f380b4-df36-414c-a5a9-6e5017be68ef"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC score: 0.8980329185066239\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#29. Train a Random Forest Regressor and analyze feature importance scores.\n",
        "\n",
        "# Generate a sample regression dataset\n",
        "X, y = make_regression(n_samples=1000, n_features=20, n_informative=15, noise=0.1, random_state=42)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Random Forest Regressor\n",
        "rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_regressor.fit(X_train, y_train)\n",
        "\n",
        "# Analyze feature importance\n",
        "feature_importances = rf_regressor.feature_importances_\n",
        "for i, importance in enumerate(feature_importances):\n",
        "    print(f\"Feature {i}: {importance}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPuPi_eopp_X",
        "outputId": "7d4e9b0c-3b11-49d4-b1d9-665621141947"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature 0: 0.06904293598595823\n",
            "Feature 1: 0.009042337559013909\n",
            "Feature 2: 0.14309732660571184\n",
            "Feature 3: 0.20122708290912694\n",
            "Feature 4: 0.011642259202869282\n",
            "Feature 5: 0.01259650864825533\n",
            "Feature 6: 0.028812202868111893\n",
            "Feature 7: 0.015838524861520792\n",
            "Feature 8: 0.09474885079128054\n",
            "Feature 9: 0.07164069800025094\n",
            "Feature 10: 0.015814236374502234\n",
            "Feature 11: 0.01126425872635175\n",
            "Feature 12: 0.04335766592970125\n",
            "Feature 13: 0.09465702709958723\n",
            "Feature 14: 0.09834510967003719\n",
            "Feature 15: 0.011832442363729476\n",
            "Feature 16: 0.021972460001794022\n",
            "Feature 17: 0.012186523093056102\n",
            "Feature 18: 0.022504826874075196\n",
            "Feature 19: 0.010376722435065775\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#30. Train an ensemble model using both Bagging and Random Forest and compare accuracy.\n",
        "\n",
        "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "# Generate a sample dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=42)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Bagging Classifier\n",
        "bagging_clf = BaggingClassifier(random_state=42)\n",
        "bagging_clf.fit(X_train, y_train)\n",
        "bagging_predictions = bagging_clf.predict(X_test)\n",
        "bagging_accuracy = accuracy_score(y_test, bagging_predictions)\n",
        "print(f\"Bagging Classifier Accuracy: {bagging_accuracy}\")\n",
        "\n",
        "# Random Forest Classifier\n",
        "rf_clf = RandomForestClassifier(random_state=42)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "rf_predictions = rf_clf.predict(X_test)\n",
        "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
        "print(f\"Random Forest Classifier Accuracy: {rf_accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9J-4Iuspv9A",
        "outputId": "6405c1e2-ec26-42b3-8ca7-a4aa7419fd69"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Classifier Accuracy: 0.865\n",
            "Random Forest Classifier Accuracy: 0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#31. Train a Random Forest Classifier and tune hyperparameters using GridSearchCV.\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a RandomForestClassifier\n",
        "rf_classifier = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Define the parameter grid for hyperparameter tuning\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Perform GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best hyperparameters and accuracy\n",
        "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
        "print(\"Best Accuracy:\", grid_search.best_score_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b40VEsTRp4ZT",
        "outputId": "d5ed53c3-8b4b-404d-bca2-3238b8aa4e39"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
            "Best Accuracy: 0.9626373626373625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#32. Train a Bagging Regressor with different numbers of base estimators and compare performance.\n",
        "\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import make_regression\n",
        "\n",
        "# Generate a sample regression dataset\n",
        "X, y = make_regression(n_samples=1000, n_features=20, n_informative=15, noise=0.1, random_state=42)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Number of base estimators to try\n",
        "n_estimators_list = [10, 50, 100, 200]\n",
        "\n",
        "for n_estimators in n_estimators_list:\n",
        "    # Create a Bagging Regressor with Decision Trees as base estimators\n",
        "    bagging_reg = BaggingRegressor(DecisionTreeRegressor(), n_estimators=n_estimators, random_state=42)\n",
        "\n",
        "    # Train the model\n",
        "    bagging_reg.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test set\n",
        "    y_pred = bagging_reg.predict(X_test)\n",
        "\n",
        "    # Evaluate the model using Mean Squared Error\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    print(f\"Mean Squared Error with {n_estimators} estimators: {mse}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unXtdzPKqRUS",
        "outputId": "eebc92f3-3411-40a1-8c5c-a70bbf65f0ed"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error with 10 estimators: 17478.013564943885\n",
            "Mean Squared Error with 50 estimators: 15431.792670507799\n",
            "Mean Squared Error with 100 estimators: 15815.26660224182\n",
            "Mean Squared Error with 200 estimators: 15411.593860296314\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#33. Train a Random Forest Classifier and analyze misclassified samples.\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Load the Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train a Random Forest Classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = rf_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model accuracy: {accuracy}\")\n",
        "\n",
        "# Analyze misclassified samples\n",
        "misclassified_indices = (y_test != y_pred)\n",
        "misclassified_samples = X_test[misclassified_indices]\n",
        "misclassified_true_labels = y_test[misclassified_indices]\n",
        "misclassified_predicted_labels = y_pred[misclassified_indices]\n",
        "\n",
        "# Print or further analyze misclassified samples\n",
        "print(\"Misclassified Samples:\")\n",
        "for i in range(len(misclassified_samples)):\n",
        "  print(f\"Sample {i+1}: True Label - {misclassified_true_labels[i]}, Predicted Label - {misclassified_predicted_labels[i]}\")\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(f\"\\nConfusion Matrix:\\n{cm}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbcBzwEZq2F_",
        "outputId": "5223effa-a55b-4232-bff5-e6540a153d90"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy: 0.9649122807017544\n",
            "Misclassified Samples:\n",
            "Sample 1: True Label - 1, Predicted Label - 0\n",
            "Sample 2: True Label - 0, Predicted Label - 1\n",
            "Sample 3: True Label - 0, Predicted Label - 1\n",
            "Sample 4: True Label - 0, Predicted Label - 1\n",
            "\n",
            "Confusion Matrix:\n",
            "[[40  3]\n",
            " [ 1 70]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#34. Train a Bagging Classifier and compare its performance with a single Decision Tree Classifier.\n",
        "\n",
        "# Create a single Decision Tree Classifier\n",
        "dt_clf = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Train the single decision tree model\n",
        "dt_clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set using the single decision tree\n",
        "dt_y_pred = dt_clf.predict(X_test)\n",
        "\n",
        "# Evaluate the single decision tree model\n",
        "dt_accuracy = accuracy_score(y_test, dt_y_pred)\n",
        "print(f\"Single Decision Tree accuracy: {dt_accuracy}\")\n",
        "\n",
        "print(f\"Bagging Classifier accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBNlCqDtrA8I",
        "outputId": "270e62ea-1f52-4491-c3ad-58ba0908dea0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Single Decision Tree accuracy: 0.9473684210526315\n",
            "Bagging Classifier accuracy: 0.9649122807017544\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#35. Train a Random Forest Classifier and visualize the confusion matrix.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Assuming 'y_test' and 'y_pred' are available from the previous Random Forest Classifier training\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Plot the confusion matrix using seaborn\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False,\n",
        "            xticklabels=['Predicted 0', 'Predicted 1'],\n",
        "            yticklabels=['Actual 0', 'Actual 1'])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "YFE2B5j7rKC1",
        "outputId": "6582d344-2f09-4cc4-9db0-32ce9ea1b08e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#36. Train a Stacking Classifier using Decision Trees, SVM, and Logistic Regression, and compare accuracy.\n",
        "\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "# Generate a sample dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=42)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define base estimators\n",
        "estimators = [\n",
        "    ('dt', DecisionTreeClassifier()),\n",
        "    ('svm', SVC()),\n",
        "    ('lr', LogisticRegression())\n",
        "]\n",
        "\n",
        "# Define the stacking classifier\n",
        "stacking_clf = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
        "\n",
        "# Train the stacking classifier\n",
        "stacking_clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = stacking_clf.predict(X_test)\n",
        "\n",
        "# Evaluate the stacking classifier's accuracy\n",
        "stacking_accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Stacking Classifier Accuracy: {stacking_accuracy}\")\n",
        "\n",
        "\n",
        "# Train individual classifiers for comparison\n",
        "for name, estimator in estimators:\n",
        "    estimator.fit(X_train, y_train)\n",
        "    y_pred = estimator.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"{name} Accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vH5QAfHdrXaj",
        "outputId": "0e032675-d80a-4ef8-a48a-172c579dc45a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacking Classifier Accuracy: 0.93\n",
            "dt Accuracy: 0.795\n",
            "svm Accuracy: 0.935\n",
            "lr Accuracy: 0.825\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#37. Train a Random Forest Classifier and print the top 5 most important features.\n",
        "\n",
        "# Load the Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train a Random Forest Classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Get feature importances\n",
        "importances = rf_classifier.feature_importances_\n",
        "\n",
        "# Get the indices of the top 5 most important features\n",
        "indices = importances.argsort()[-5:][::-1]\n",
        "\n",
        "# Print the top 5 most important features\n",
        "print(\"Top 5 most important features:\")\n",
        "for i in indices:\n",
        "  print(f\"{data.feature_names[i]}: {importances[i]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWNZTjizrhlX",
        "outputId": "0603bccd-33ac-4f4b-9372-94d528cbbd96"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 most important features:\n",
            "worst area: 0.15389236463205394\n",
            "worst concave points: 0.14466326620735528\n",
            "mean concave points: 0.10620998844591638\n",
            "worst radius: 0.07798687515738047\n",
            "mean concavity: 0.06800084191430111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#38. Train a Bagging Classifier and evaluate performance using Precision, Recall, and F1-score.\n",
        "\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "# Generate a sample dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=42)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a Bagging Classifier with Decision Trees as base estimators\n",
        "bagging_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "bagging_clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = bagging_clf.predict(X_test)\n",
        "\n",
        "# Evaluate the model using precision, recall, and F1-score\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1-score: {f1}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9cCEOKVrocG",
        "outputId": "5900840b-a6c7-41e0-dcba-4910c3b1f7a2"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.8888888888888888\n",
            "Recall: 0.851063829787234\n",
            "F1-score: 0.8695652173913043\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#39. Train a Random Forest Classifier and analyze the effect of max_depth on accuracy.\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Assuming X and y are your features and target variable\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Max depth values to test\n",
        "max_depths = [None, 5, 10, 15, 20]\n",
        "\n",
        "for max_depth in max_depths:\n",
        "  # Train the model\n",
        "  rf_classifier = RandomForestClassifier(n_estimators=100, max_depth=max_depth, random_state=42)\n",
        "  rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "  # Make predictions\n",
        "  y_pred = rf_classifier.predict(X_test)\n",
        "\n",
        "  # Evaluate accuracy\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  print(f\"Accuracy with max_depth={max_depth}: {accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JctZLrsysFCa",
        "outputId": "cc5220ac-84ad-42cb-93dd-5472c237b105"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with max_depth=None: 0.9\n",
            "Accuracy with max_depth=5: 0.88\n",
            "Accuracy with max_depth=10: 0.9\n",
            "Accuracy with max_depth=15: 0.9\n",
            "Accuracy with max_depth=20: 0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#40.  Train a Bagging Regressor using different base estimators (DecisionTree and KNeighbors) and compare performance.\n",
        "\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Generate a sample regression dataset\n",
        "X, y = make_regression(n_samples=1000, n_features=20, n_informative=15, noise=0.1, random_state=42)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train a Bagging Regressor with Decision Tree\n",
        "bagging_reg_dt = BaggingRegressor(DecisionTreeRegressor(), n_estimators=100, random_state=42)\n",
        "bagging_reg_dt.fit(X_train, y_train)\n",
        "y_pred_dt = bagging_reg_dt.predict(X_test)\n",
        "mse_dt = mean_squared_error(y_test, y_pred_dt)\n",
        "print(f\"Bagging Regressor (Decision Tree) MSE: {mse_dt}\")\n",
        "\n",
        "# Create and train a Bagging Regressor with KNeighborsRegressor\n",
        "bagging_reg_knn = BaggingRegressor(KNeighborsRegressor(), n_estimators=100, random_state=42)\n",
        "bagging_reg_knn.fit(X_train, y_train)\n",
        "y_pred_knn = bagging_reg_knn.predict(X_test)\n",
        "mse_knn = mean_squared_error(y_test, y_pred_knn)\n",
        "print(f\"Bagging Regressor (KNeighbors) MSE: {mse_knn}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEGin-B1sWz4",
        "outputId": "f0993bcd-8df4-4c3d-b5ac-953b1e8a92ec"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Regressor (Decision Tree) MSE: 15815.26660224182\n",
            "Bagging Regressor (KNeighbors) MSE: 19135.010133135234\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#41. Train a Random Forest Classifier and evaluate its performance using ROC-AUC Score.\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Load the Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train a Random Forest Classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_proba = rf_classifier.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Evaluate the model using ROC-AUC score\n",
        "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "print(f\"ROC-AUC Score: {roc_auc}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8ZyT0sJshc9",
        "outputId": "92728c3f-d80f-4de0-9d2a-e219a9cf2b0a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC Score: 0.9952505732066819\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#42. Train a Bagging Classifier and evaluate its performance using cross-validation.\n",
        "\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "# Generate a sample dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=42)\n",
        "\n",
        "# Create a Bagging Classifier\n",
        "bagging_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=100, random_state=42)\n",
        "\n",
        "# Evaluate the model using cross-validation\n",
        "cv_scores = cross_val_score(bagging_clf, X, y, cv=5, scoring='accuracy') # 5-fold cross-validation\n",
        "\n",
        "# Print the cross-validation scores\n",
        "print(\"Cross-validation scores:\", cv_scores)\n",
        "print(\"Mean accuracy:\", cv_scores.mean())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mb_8Veb3so-t",
        "outputId": "b3d4c7ec-6284-46f7-f0b5-fe14b0e9d658"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation scores: [0.86  0.895 0.915 0.885 0.905]\n",
            "Mean accuracy: 0.892\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#43. Train a Random Forest Classifier and plot the Precision-Recall curve.\n",
        "\n",
        "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generate a sample dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=42)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train a Random Forest Classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities for the positive class\n",
        "y_scores = rf_classifier.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Compute precision-recall curve\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, y_scores)\n",
        "\n",
        "# Compute average precision score\n",
        "average_precision = average_precision_score(y_test, y_scores)\n",
        "\n",
        "# Plot the Precision-Recall curve\n",
        "plt.plot(recall, precision, label=f'AP={average_precision:.2f}')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "Fs5pXBRqs3Uh",
        "outputId": "f766ebd2-6355-4fd2-935e-c545ad3fd07f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAQzNJREFUeJzt3XlclWX+//H34cA5gGxugCK5L7mkhumgmWUoLjljNWWauUya67dGphot06mmyBazKbfMbZomMbPGKdMUs1Ipy+1X5r6kqSBWssp2zv37w+HkCTBA4MDt6/l43A8917muc3/uC+q8vVeLYRiGAAAATMLL0wUAAABUJMINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINcBUaNWqUmjRpUqYxmzdvlsVi0ebNmyulppru5ptv1s033+x6ffz4cVksFi1btsxjNQFXK8INUAWWLVsmi8XiWnx9fdWqVStNnjxZKSkpni6v2isMCoWLl5eX6tSpo/79+yspKcnT5VWIlJQUPfzww2rTpo38/f1Vq1YtRUVF6e9//7vOnz/v6fKAGsXb0wUAV5OnnnpKTZs2VU5OjrZs2aL58+dr7dq1+vbbb+Xv719ldSxatEhOp7NMY2666SZduHBBNputkqr6bUOHDtWAAQPkcDh08OBBzZs3T7fccou++uordejQwWN1XamvvvpKAwYMUGZmpoYPH66oqChJ0tdff63nnntOn332mT7++GMPVwnUHIQboAr1799fXbp0kSSNGTNGdevW1ezZs/Wf//xHQ4cOLXZMVlaWatWqVaF1+Pj4lHmMl5eXfH19K7SOsrr++us1fPhw1+uePXuqf//+mj9/vubNm+fBysrv/Pnzuv3222W1WrVr1y61adPG7f1nnnlGixYtqpB1VcbvElAdcVgK8KDevXtLko4dOybp4rkwAQEBOnLkiAYMGKDAwEDde++9kiSn06k5c+aoXbt28vX1VVhYmMaNG6eff/65yOd+9NFH6tWrlwIDAxUUFKQbbrhB//73v13vF3fOzYoVKxQVFeUa06FDB73yyiuu90s65+add95RVFSU/Pz8VK9ePQ0fPlynTp1y61O4XadOndLgwYMVEBCg+vXr6+GHH5bD4Sj3/PXs2VOSdOTIEbf28+fP689//rMiIyNlt9vVokULzZo1q8jeKqfTqVdeeUUdOnSQr6+v6tevr379+unrr7929Vm6dKl69+6t0NBQ2e12tW3bVvPnzy93zb+2cOFCnTp1SrNnzy4SbCQpLCxM06dPd722WCz629/+VqRfkyZNNGrUKNfrwkOhn376qSZOnKjQ0FA1atRIq1atcrUXV4vFYtG3337ratu/f7/++Mc/qk6dOvL19VWXLl20Zs2aK9tooJKx5wbwoMIv5bp167raCgoKFBsbqxtvvFEvvvii63DVuHHjtGzZMo0ePVoPPvigjh07ptdee027du3S1q1bXXtjli1bpj/96U9q166dpk2bppCQEO3atUvr1q3TsGHDiq1jw4YNGjp0qG699VbNmjVLkrRv3z5t3bpVDz30UIn1F9Zzww03KD4+XikpKXrllVe0detW7dq1SyEhIa6+DodDsbGx6tatm1588UVt3LhRL730kpo3b64JEyaUa/6OHz8uSapdu7arLTs7W7169dKpU6c0btw4XXPNNdq2bZumTZumM2fOaM6cOa6+999/v5YtW6b+/ftrzJgxKigo0Oeff64vvvjCtYdt/vz5ateunX7/+9/L29tb//3vfzVx4kQ5nU5NmjSpXHVfas2aNfLz89Mf//jHK/6s4kycOFH169fXjBkzlJWVpYEDByogIEArV65Ur1693PomJCSoXbt2at++vSRp79696tGjhyIiIjR16lTVqlVLK1eu1ODBg/Xuu+/q9ttvr5SagStmAKh0S5cuNSQZGzduNFJTU42TJ08aK1asMOrWrWv4+fkZP/zwg2EYhjFy5EhDkjF16lS38Z9//rkhyXjrrbfc2tetW+fWfv78eSMwMNDo1q2bceHCBbe+TqfT9feRI0cajRs3dr1+6KGHjKCgIKOgoKDEbfjkk08MScYnn3xiGIZh5OXlGaGhoUb79u3d1vXBBx8YkowZM2a4rU+S8dRTT7l9ZufOnY2oqKgS11no2LFjhiTjySefNFJTU43k5GTj888/N2644QZDkvHOO++4+j799NNGrVq1jIMHD7p9xtSpUw2r1WqcOHHCMAzD2LRpkyHJePDBB4us79K5ys7OLvJ+bGys0axZM7e2Xr16Gb169SpS89KlSy+7bbVr1zY6dux42T6XkmTMnDmzSHvjxo2NkSNHul4X/s7deOONRX6uQ4cONUJDQ93az5w5Y3h5ebn9jG699VajQ4cORk5OjqvN6XQa3bt3N1q2bFnqmoGqxmEpoArFxMSofv36ioyM1D333KOAgAC99957ioiIcOv36z0Z77zzjoKDg9WnTx+dO3fOtURFRSkgIECffPKJpIt7YDIyMjR16tQi58dYLJYS6woJCVFWVpY2bNhQ6m35+uuvdfbsWU2cONFtXQMHDlSbNm304YcfFhkzfvx4t9c9e/bU0aNHS73OmTNnqn79+goPD1fPnj21b98+vfTSS257Pd555x317NlTtWvXdpurmJgYORwOffbZZ5Kkd999VxaLRTNnziyynkvnys/Pz/X3tLQ0nTt3Tr169dLRo0eVlpZW6tpLkp6ersDAwCv+nJKMHTtWVqvVrW3IkCE6e/as2yHGVatWyel0asiQIZKkn376SZs2bdLdd9+tjIwM1zz++OOPio2N1aFDh4ocfgSqCw5LAVVo7ty5atWqlby9vRUWFqbWrVvLy8v93xje3t5q1KiRW9uhQ4eUlpam0NDQYj/37Nmzkn45zFV4WKG0Jk6cqJUrV6p///6KiIhQ3759dffdd6tfv34ljvn+++8lSa1bty7yXps2bbRlyxa3tsJzWi5Vu3Ztt3OGUlNT3c7BCQgIUEBAgOv1Aw88oLvuuks5OTnatGmT/vGPfxQ5Z+fQoUP6f//v/xVZV6FL56phw4aqU6dOidsoSVu3btXMmTOVlJSk7Oxst/fS0tIUHBx82fG/JSgoSBkZGVf0GZfTtGnTIm39+vVTcHCwEhISdOutt0q6eEiqU6dOatWqlSTp8OHDMgxDTzzxhJ544oliP/vs2bNFgjlQHRBugCrUtWtX17kcJbHb7UUCj9PpVGhoqN56661ix5T0RV5aoaGh2r17t9avX6+PPvpIH330kZYuXaoRI0Zo+fLlV/TZhX6996A4N9xwgys0SRf31Fx68mzLli0VExMjSbrttttktVo1depU3XLLLa55dTqd6tOnjx599NFi11H45V0aR44c0a233qo2bdpo9uzZioyMlM1m09q1a/Xyyy+X+XL64rRp00a7d+9WXl7eFV1mX9KJ2ZfueSpkt9s1ePBgvffee5o3b55SUlK0detWPfvss64+hdv28MMPKzY2ttjPbtGiRbnrBSoT4QaoAZo3b66NGzeqR48exX5ZXdpPkr799tsyf/HYbDYNGjRIgwYNktPp1MSJE7Vw4UI98cQTxX5W48aNJUkHDhxwXfVV6MCBA673y+Ktt97ShQsXXK+bNWt22f6PP/64Fi1apOnTp2vdunWSLs5BZmamKwSVpHnz5lq/fr1++umnEvfe/Pe//1Vubq7WrFmja665xtVeeBiwIgwaNEhJSUl69913S7wdwKVq165d5KZ+eXl5OnPmTJnWO2TIEC1fvlyJiYnat2+fDMNwHZKSfpl7Hx+f35xLoLrhnBugBrj77rvlcDj09NNPF3mvoKDA9WXXt29fBQYGKj4+Xjk5OW79DMMo8fN//PFHt9deXl667rrrJEm5ubnFjunSpYtCQ0O1YMECtz4fffSR9u3bp4EDB5Zq2y7Vo0cPxcTEuJbfCjchISEaN26c1q9fr927d0u6OFdJSUlav359kf7nz59XQUGBJOnOO++UYRh68skni/QrnKvCvU2Xzl1aWpqWLl1a5m0ryfjx49WgQQP95S9/0cGDB4u8f/bsWf397393vW7evLnrvKFCr7/+epkvqY+JiVGdOnWUkJCghIQEde3a1e0QVmhoqG6++WYtXLiw2OCUmppapvUBVYk9N0AN0KtXL40bN07x8fHavXu3+vbtKx8fHx06dEjvvPOOXnnlFf3xj39UUFCQXn75ZY0ZM0Y33HCDhg0bptq1a2vPnj3Kzs4u8RDTmDFj9NNPP6l3795q1KiRvv/+e7366qvq1KmTrr322mLH+Pj4aNasWRo9erR69eqloUOHui4Fb9KkiaZMmVKZU+Ly0EMPac6cOXruuee0YsUKPfLII1qzZo1uu+02jRo1SlFRUcrKytI333yjVatW6fjx46pXr55uueUW3XffffrHP/6hQ4cOqV+/fnI6nfr88891yy23aPLkyerbt69rj9a4ceOUmZmpRYsWKTQ0tMx7SkpSu3ZtvffeexowYIA6derkdofinTt36u2331Z0dLSr/5gxYzR+/Hjdeeed6tOnj/bs2aP169erXr16ZVqvj4+P7rjjDq1YsUJZWVl68cUXi/SZO3eubrzxRnXo0EFjx45Vs2bNlJKSoqSkJP3www/as2fPlW08UFk8eakWcLUovCz3q6++umy/kSNHGrVq1Srx/ddff92Iiooy/Pz8jMDAQKNDhw7Go48+apw+fdqt35o1a4zu3bsbfn5+RlBQkNG1a1fj7bffdlvPpZeCr1q1yujbt68RGhpq2Gw245prrjHGjRtnnDlzxtXn15eCF0pISDA6d+5s2O12o06dOsa9997rurT9t7Zr5syZRmn+N1R4WfULL7xQ7PujRo0yrFarcfjwYcMwDCMjI8OYNm2a0aJFC8Nmsxn16tUzunfvbrz44otGXl6ea1xBQYHxwgsvGG3atDFsNptRv359o3///saOHTvc5vK6664zfH19jSZNmhizZs0ylixZYkgyjh075upX3kvBC50+fdqYMmWK0apVK8PX19fw9/c3oqKijGeeecZIS0tz9XM4HMZf//pXo169eoa/v78RGxtrHD58uMRLwS/3O7dhwwZDkmGxWIyTJ08W2+fIkSPGiBEjjPDwcMPHx8eIiIgwbrvtNmPVqlWl2i7AEyyGcZl91QAAADUM59wAAABTIdwAAABTIdwAAABTIdwAAABTIdwAAABTIdwAAABTuepu4ud0OnX69GkFBgZe9inJAACg+jAMQxkZGWrYsGGR5+/92lUXbk6fPq3IyEhPlwEAAMrh5MmTatSo0WX7XHXhJjAwUNLFyQkKCvJwNQAAoDTS09MVGRnp+h6/nKsu3BQeigoKCiLcAABQw5TmlBJOKAYAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKbi0XDz2WefadCgQWrYsKEsFovef//93xyzefNmXX/99bLb7WrRooWWLVtW6XUCAICaw6PhJisrSx07dtTcuXNL1f/YsWMaOHCgbrnlFu3evVt//vOfNWbMGK1fv76SKwUAADWFRx+c2b9/f/Xv37/U/RcsWKCmTZvqpZdekiRde+212rJli15++WXFxsZWVpmlklvgUGpGrkdrAICKYLFY1DDYt1QPKASqoxr1VPCkpCTFxMS4tcXGxurPf/5ziWNyc3OVm/tL6EhPT6+U2vaeTtcd87ZVymcDQFXrGBmiZaNuUO1aNk+XApRZjQo3ycnJCgsLc2sLCwtTenq6Lly4ID8/vyJj4uPj9eSTT1Z6bRZJdm/OzwZQ8+U7nNpz8ryGLvpCb43pproBdk+XBJRJjQo35TFt2jTFxcW5XqenpysyMrLC19P5mto68PfSH2IDgOrq8NkMDV30pfYnZ2jYoi/11thuqkfAQQ1So3Y1hIeHKyUlxa0tJSVFQUFBxe61kSS73a6goCC3BQBQshahgVrxwO8UGmjXgZQMDX39C84pRI1So8JNdHS0EhMT3do2bNig6OhoD1UEAObUvH6AEsZFKzzIV4fOZuqe15N0Nj3H02UBpeLRcJOZmandu3dr9+7dki5e6r17926dOHFC0sVDSiNGjHD1Hz9+vI4ePapHH31U+/fv17x587Ry5UpNmTLFE+UDgKk1rVdLCeN+p4bBvjqSmqV7Xv9CyWkEHFR/Hg03X3/9tTp37qzOnTtLkuLi4tS5c2fNmDFDknTmzBlX0JGkpk2b6sMPP9SGDRvUsWNHvfTSS3rjjTc8fhk4AJhV47q1lDAuWhEhfjp6Lkv3vJ6kM2kXPF0WcFkWwzAMTxdRldLT0xUcHKy0tDTOvwGAUjr5U7aGLvpCP/x8QdfU8dfbD/xOESHFn+sIVIayfH8TbgAApXLq/AUNff0LnfgpW5F1/PT22N+pUW3/Uo83DEN5DqfyCpzKdxjKK7j49zyHQ7kFv2p3OGT3tiq6WV15eXEzQRBuLotwAwDldybtYsA5/mO2woN81T4iWHkOp3LzfwkohQEmr8Cp3ALHJYHFWeb1/bVfG024uXklbAlqGsLNZRBuAODKJKflaNiiL3T0XNYVfY63l0U2b6+Li9VLPlYv2f/32jCkAykZ8rdZ9cnDNyssyLeCqkdNVZbvb9PfxA8AULHCg3313sQeWr83WQ7DcAUSu7fVFVQuvvZye31pkLFZvS57uMkwDN0xf5t2nTiv59cd0Et3d6zCLURNx54bAEC1tPvkeQ2eu1WS9J9JPdQxMsSzBcGjyvL9XaNu4gcAuHp0igzRHddHSJKe/O9eXWX/FscVINwAAKqtv/ZrI3+bVTtPnNeaPac9XQ5qCM65AQBUW2FBvpp0Swu9sP6A4tfuV5+2YfK3VfxXl2EYysl3KjuvQNl5DuXkO5Sdd3G5kF+gC3kX37uQ71BegVO3XhumpvVqVXgdqBiEGwBAtXb/jU319vYT+uHnC5q/+YjG9Wqu7NwCZeU5lJV7MYxk5RUoO7fwzwJl5ztcry/kOZSV57jYnudQdr5DF/IKlJX7S4i5kO8oU00bvktRwjiea1hdEW4AANWar49Vjw24VhPf2qlXNx3Wq5sOV+r67N5e8rdZ5W/zlp/NKj8fq/xsVvnbrMrKLdBXx39W2oX8Sq0BV4ZwAwCo9vq3D9ctrevrkwOpkiQvi1TL5i1/u9X1p7/NW7X+F0pq/e+1//9Cid//3vOz/dKv8O+Xhhc/H+tlL1Hfevic7n3jy6rabJQT4QYAUO1ZLBYtGXWDfs7Ol7/NKru3lywWHsuA4hFuAAA1gsViUZ1aNk+XgRqAS8EBAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpeDzczJ07V02aNJGvr6+6deum7du3l9g3Pz9fTz31lJo3by5fX1917NhR69atq8JqAQBAdefRcJOQkKC4uDjNnDlTO3fuVMeOHRUbG6uzZ88W23/69OlauHChXn31VX333XcaP368br/9du3atauKKwcAANWVR8PN7NmzNXbsWI0ePVpt27bVggUL5O/vryVLlhTb/80339Rjjz2mAQMGqFmzZpowYYIGDBigl156qYorBwAA1ZXHwk1eXp527NihmJiYX4rx8lJMTIySkpKKHZObmytfX1+3Nj8/P23ZsqXE9eTm5io9Pd1tAQAA5uXtqRWfO3dODodDYWFhbu1hYWHav39/sWNiY2M1e/Zs3XTTTWrevLkSExO1evVqORyOEtcTHx+vJ598skJrBwBc3c5l5ump/36no+cydTQ1Sz9n5Sn+zg667bqGni4NqgYnFJfFK6+8opYtW6pNmzay2WyaPHmyRo8eLS+vkjdj2rRpSktLcy0nT56swooBAGbiZbFIks5l5mrJ1mPafCBVJ37KVkZugT49kOrh6lDIY3tu6tWrJ6vVqpSUFLf2lJQUhYeHFzumfv36ev/995WTk6Mff/xRDRs21NSpU9WsWbMS12O322W32yu0dgDA1en6xiG67boGys5zqFm9WmpWP0C7Tvysd3b84OnScAmPhRubzaaoqCglJiZq8ODBkiSn06nExERNnjz5smN9fX0VERGh/Px8vfvuu7r77ruroGIAwNXO7m3Va8Oud2tLu5DvoWpQEo+FG0mKi4vTyJEj1aVLF3Xt2lVz5sxRVlaWRo8eLUkaMWKEIiIiFB8fL0n68ssvderUKXXq1EmnTp3S3/72NzmdTj366KOe3AwAAC7LMAydzcjV4bOZOpKa6frzaGqW2kcEa+HwKHl5WTxdpml4NNwMGTJEqampmjFjhpKTk9WpUyetW7fOdZLxiRMn3M6nycnJ0fTp03X06FEFBARowIABevPNNxUSEuKhLQAA4Bf5Dqe+/zHbLcAcOZupI6lZyswtKHbMmbQcfX74nHq1ql/F1ZqXxTAMw9NFVKX09HQFBwcrLS1NQUFBni4HAFDDzd98RLPW7Zefj1X5DqcKnMV/rVq9LGpcx1/N6geoeWgttagfoG1HftR7u07p5tb1tWx01yquvGYpy/e3R/fcAABQ09ULsEmSLuRfvC2Jv82q5vUD1CI0QM3r1/rfnwG6pq6/7N5Wt7Fdm9bR+7tPafOBVB1JzVTz+gFVXr8ZEW4AALgCf+gUoWA/H/nZrGoRGqDwIF9ZLKU7f6Zx3Vq6tU2oNu47q+XbjuupP7Sv5GqvDjXqPjcAAFQ3Nm8v9W0Xrp4t66tBsF+pg02h0T2aSpJW7fiBK68qCOEGAAAP6t68rlqHBSo7z6F3vuZGsxWBcAMAgAdZLBaN6tFEkrQ86bgcJZyQjNIj3AAA4GGDO0UoxN9HJ3+6oMR9Kb894Fdy8h367nS6fvg5uxKqq3k4oRgAAA/zs1l1zw3XaMGnR7R063H1bVf8Y4gu5Dl0JDVTB1MydDAlU4fPZujQ2Uyd/ClbTkOyWb20dWpv1Q+8uh87RLgBAKAaGBHdWIs+P6qkoz9qz8nz8rZadCjllyBz6GyGTvyUrcvdnS7P4VRKeg7hxtMFAAAAqWGIn/q1C9eH35zRH+ZuLbFfbX8ftQoLVMuwALUKC1SL0AC1DA3UoFe3KDk9pworrr4INwAAVBMP3NRM6/Ymy+E0FOzno1ZhAWoZFqhWoQH/CzSBqhdgK/Zy8zJegW5qhBsAAKqJjpEh2vLXW+RlsSg00F7me+bgIsINAADVSINgP0+XUONxKTgAADAVwg0AADAVwg0AADAVwg0AACZ1Ic8h43I3xjEpTigGAMBElm87rrQL+dqffPGmf12b1NHK8dGeLqtKEW4AADABr/9dNv7Ojh/c2r/6/idPlONRhBsAAExgbM+m+u//O6Pm9WupTXiQwoJ8NenfOz1dlkcQbgAAMIFRPZpqVI+mrtepGbmX7Z+T79ChlEztO5Ou1Mxc3RXVSKFBvpVdZpUg3AAAYGKGIaWk5+i7M+n67nS69p25uBw7lyXnJecaZ+QUaGr/Np4rtAIRbgAAMLluzyYW216nlk02q5eS03OUmZtfxVVVHsINAAAmFOjrrWA/H6VdyJfVy6Jm9Wrp2gZB/1sC1bZBkOoH2vVK4iHN2XjI0+VWKMINAAAm5Otj1cdTbtLZ9Fy1DAuQr4/V0yVVGcINAAAmFRbkqzCTnCRcFtyhGAAAmArhBgAAmArhBgAAmArhBgAAmArhBgAAmArhBgAAmArhBgAAmArhBgAAmArhBgAAmArhBgAAmArhBgCAq5jf/5459fHeFO068bOHq6kYhBsAAK5id0Y1UsvQAJ3NyNWQhV8o4asTni7pihFuAAC4itULsOu9ST0U2y5MeQ6n/vruN5r+/jfKK3B6urRyI9wAAHCVC7B7a/69UfpLn1ayWKR/fXFC977xhXLyHZ4urVwINwAAQF5eFv3frS21eGQXBdq99dXxn7XhuxRPl1UuhBsAAODSu02YujatI0m6kMeeGwAAAI/z9nQBAACgejr5c7ZWfn1Se06e154fzsvf5q0Zt7VV+4hgT5d2WYQbAABQrFc3HS7Sdsf8bXritrYa3u0aWSwWD1T12zgsBQAA3LQKD5R08QZ/XZvW0QM3NdNrwzor5tpQ5RU49cT732ryv3cpPSffw5UWz2IYhuHpIqpSenq6goODlZaWpqCgIE+XAwBAtWMYhpLTc1Q/wC5vq5db++Itx/TcR/tV4DR0TR1/zbv3+io5TFWW72/23AAAADcWi0UNgv3cgk1h+5iezbRqQnc1qu2nEz9la/K/d3qoypIRbgAAQJl0igzRv+7vJkk6df6Ch6spinADAADKzPd/D9ysjgg3AADAVAg3AADAVAg3AADAVDwebubOnasmTZrI19dX3bp10/bt2y/bf86cOWrdurX8/PwUGRmpKVOmKCcnp4qqBQAA1Z1Hw01CQoLi4uI0c+ZM7dy5Ux07dlRsbKzOnj1bbP9///vfmjp1qmbOnKl9+/Zp8eLFSkhI0GOPPVbFlQMAgOrKo+Fm9uzZGjt2rEaPHq22bdtqwYIF8vf315IlS4rtv23bNvXo0UPDhg1TkyZN1LdvXw0dOvQ39/YAAICrh8fCTV5ennbs2KGYmJhfivHyUkxMjJKSkood0717d+3YscMVZo4ePaq1a9dqwIABVVIzAACo/jz24Mxz587J4XAoLCzMrT0sLEz79+8vdsywYcN07tw53XjjjTIMQwUFBRo/fvxlD0vl5uYqNzfX9To9Pb1iNgAAAFRLHj+huCw2b96sZ599VvPmzdPOnTu1evVqffjhh3r66adLHBMfH6/g4GDXEhkZWYUVAwCAquaxPTf16tWT1WpVSkqKW3tKSorCw8OLHfPEE0/ovvvu05gxYyRJHTp0UFZWlh544AE9/vjj8vIqmtWmTZumuLg41+v09HQCDgAAJuaxPTc2m01RUVFKTEx0tTmdTiUmJio6OrrYMdnZ2UUCjNV68fbPJT3c3G63KygoyG0BAADm5bE9N5IUFxenkSNHqkuXLuratavmzJmjrKwsjR49WpI0YsQIRUREKD4+XpI0aNAgzZ49W507d1a3bt10+PBhPfHEExo0aJAr5AAAgKubR8PNkCFDlJqaqhkzZig5OVmdOnXSunXrXCcZnzhxwm1PzfTp02WxWDR9+nSdOnVK9evX16BBg/TMM894ahMAAEA1YzFKOp5jUunp6QoODlZaWhqHqAAAKKfktBz9Lj5RPlaLDj1T+bdkKcv3d426WgoAAOC3EG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICplOsOxQ6HQ8uWLVNiYqLOnj0rp9Pp9v6mTZsqpDgAAICyKle4eeihh7Rs2TINHDhQ7du3l8Viqei6AAAAyqVc4WbFihVauXKlBgyo/NstAwAAlEW5zrmx2Wxq0aJFRdcCAABwxcoVbv7yl7/olVde0VX2zE0AAFADlOuw1JYtW/TJJ5/oo48+Urt27eTj4+P2/urVqyukOAAAgLIqV7gJCQnR7bffXtG1AAAAXLFyhZulS5dWdB0AAAAVolzhplBqaqoOHDggSWrdurXq169fIUUBAACUV7lOKM7KytKf/vQnNWjQQDfddJNuuukmNWzYUPfff7+ys7MrukYAAIBSK1e4iYuL06effqr//ve/On/+vM6fP6///Oc/+vTTT/WXv/ylomsEAAAotXIdlnr33Xe1atUq3Xzzza62AQMGyM/PT3fffbfmz59fUfUBAACUSbn23GRnZyssLKxIe2hoKIelAACAR5Ur3ERHR2vmzJnKyclxtV24cEFPPvmkoqOjK6w4AACAsirXYalXXnlFsbGxatSokTp27ChJ2rNnj3x9fbV+/foKLRAAAKAsyhVu2rdvr0OHDumtt97S/v37JUlDhw7VvffeKz8/vwotEAAAoCzKfZ8bf39/jR07tiJrAQAAuGKlDjdr1qxR//795ePjozVr1ly27+9///srLgwAAKA8Sh1uBg8erOTkZIWGhmrw4MEl9rNYLHI4HBVRGwAAQJmVOtw4nc5i/w4AAFCdlOtS8OKcP3++oj4KAACg3MoVbmbNmqWEhATX67vuukt16tRRRESE9uzZU2HFAQAAlFW5ws2CBQsUGRkpSdqwYYM2btyodevWqX///nrkkUcqtEAAAICyKNel4MnJya5w88EHH+juu+9W37591aRJE3Xr1q1CCwQAACiLcu25qV27tk6ePClJWrdunWJiYiRJhmFwpRQAAPCocu25ueOOOzRs2DC1bNlSP/74o/r37y9J2rVrl1q0aFGhBQIAAJRFucLNyy+/rCZNmujkyZN6/vnnFRAQIEk6c+aMJk6cWKEFAgAAlEW5wo2Pj48efvjhIu1Tpky54oIAAACuBI9fAAAApsLjFwAAgKnw+AUAAGAqFfb4BQAAgOqgXOHmwQcf1D/+8Y8i7a+99pr+/Oc/X2lNAAAA5VaucPPuu++qR48eRdq7d++uVatWXXFRAAAA5VWucPPjjz8qODi4SHtQUJDOnTt3xUUBAACUV7nCTYsWLbRu3boi7R999JGaNWt2xUUBAACUV7lu4hcXF6fJkycrNTVVvXv3liQlJibqpZde0pw5cyqyPgAAgDIpV7j505/+pNzcXD3zzDN6+umnJUlNmjTR/PnzNWLEiAotEAAAoCzKFW4kacKECZowYYJSU1Pl5+fner4UAACAJ5X7PjcFBQXauHGjVq9eLcMwJEmnT59WZmZmhRUHAABQVuXac/P999+rX79+OnHihHJzc9WnTx8FBgZq1qxZys3N1YIFCyq6TgAAgFIp156bhx56SF26dNHPP/8sPz8/V/vtt9+uxMTECisOAACgrMq15+bzzz/Xtm3bZLPZ3NqbNGmiU6dOVUhhAAAA5VGuPTdOp7PYJ3//8MMPCgwMvOKiAAAAyqtc4aZv375u97OxWCzKzMzUzJkzNWDAgIqqDQAAoMzKFW5efPFFbd26VW3btlVOTo6GDRvmOiQ1a9asMn/e3Llz1aRJE/n6+qpbt27avn17iX1vvvlmWSyWIsvAgQPLsykAAMBkynXOTWRkpPbs2aOEhATt2bNHmZmZuv/++3Xvvfe6nWBcGgkJCYqLi9OCBQvUrVs3zZkzR7GxsTpw4IBCQ0OL9F+9erXy8vJcr3/88Ud17NhRd911V3k2BQAAmIzFKLxJTSnl5+erTZs2+uCDD3TttddecQHdunXTDTfcoNdee03SxfN5IiMj9X//93+aOnXqb46fM2eOZsyYoTNnzqhWrVq/2T89PV3BwcFKS0tTUFDQFdcPAMDVKDktR7+LT5SP1aJDz1T+KSll+f4u82EpHx8f5eTklLu4S+Xl5WnHjh2KiYn5pSAvL8XExCgpKalUn7F48WLdc889JQab3Nxcpaenuy0AAMC8ynXOzaRJkzRr1iwVFBRc0crPnTsnh8OhsLAwt/awsDAlJyf/5vjt27fr22+/1ZgxY0rsEx8fr+DgYNcSGRl5RTUDAIDqrVzn3Hz11VdKTEzUxx9/rA4dOhTZa7J69eoKKe63LF68WB06dFDXrl1L7DNt2jTFxcW5XqenpxNwAAAwsXKFm5CQEN15551XvPJ69erJarUqJSXFrT0lJUXh4eGXHZuVlaUVK1boqaeeumw/u90uu91+xbUCAICaoUzhxul06oUXXtDBgweVl5en3r17629/+1uZr5AqZLPZFBUVpcTERA0ePNi1jsTERE2ePPmyY9955x3l5uZq+PDh5Vo3AAAwpzKdc/PMM8/oscceU0BAgCIiIvSPf/xDkyZNuqIC4uLitGjRIi1fvlz79u3ThAkTlJWVpdGjR0uSRowYoWnTphUZt3jxYg0ePFh169a9ovUDAABzKdOem3/+85+aN2+exo0bJ0nauHGjBg4cqDfeeENeXuU6N1lDhgxRamqqZsyYoeTkZHXq1Enr1q1znWR84sSJIp994MABbdmyRR9//HG51gkAAMyrTPe5sdvtOnz4sNsJub6+vjp8+LAaNWpUKQVWNO5zAwDAlTPNfW4KCgrk6+vr1ubj46P8/PyyVwkAAFAJynRYyjAMjRo1yu3qo5ycHI0fP97tcvCquhQcAADg18oUbkaOHFmkjauVAABAdVKmcLN06dLKqgMAAKBClO8SJwAAgGqKcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAMrN4TR0Ju2Cp8twQ7gBAABlVjfApka1/eQ0pEGvbtXXx3/ydEkuhBsAAFBmPlYvvT32d2oTHqhzmbkauugLvfXl954uSxLhBgAAlFNkHX+tnthdAzs0UL7D0OPvfavH3vtGeQVOj9ZFuAEAAOXmb/PWa8M665HY1rJYpH9/eULxH+3zaE2EGwAAcEUsFosm3dJCM29rK0nac/K8R+sh3AAAgArRMMTP0yVIItwAAACTIdwAAABTIdwAAABTIdwAAABTIdwAAABTIdwAAABTIdwAAABTIdwAAABTIdwAAABTIdwAAABTIdwAAABTIdwAAABTIdwAAABT8Xi4mTt3rpo0aSJfX19169ZN27dvv2z/8+fPa9KkSWrQoIHsdrtatWqltWvXVlG1AACguvP25MoTEhIUFxenBQsWqFu3bpozZ45iY2N14MABhYaGFumfl5enPn36KDQ0VKtWrVJERIS+//57hYSEVH3xAACgWvJouJk9e7bGjh2r0aNHS5IWLFigDz/8UEuWLNHUqVOL9F+yZIl++uknbdu2TT4+PpKkJk2aVGXJAACgmvPYYam8vDzt2LFDMTExvxTj5aWYmBglJSUVO2bNmjWKjo7WpEmTFBYWpvbt2+vZZ5+Vw+GoqrIBAEA157E9N+fOnZPD4VBYWJhbe1hYmPbv31/smKNHj2rTpk269957tXbtWh0+fFgTJ05Ufn6+Zs6cWeyY3Nxc5ebmul6np6dX3EYAAIBqx+MnFJeF0+lUaGioXn/9dUVFRWnIkCF6/PHHtWDBghLHxMfHKzg42LVERkZWYcUAAKCqeSzc1KtXT1arVSkpKW7tKSkpCg8PL3ZMgwYN1KpVK1mtVlfbtddeq+TkZOXl5RU7Ztq0aUpLS3MtJ0+erLiNAAAA1Y7Hwo3NZlNUVJQSExNdbU6nU4mJiYqOji52TI8ePXT48GE5nU5X28GDB9WgQQPZbLZix9jtdgUFBbktAADAvDx6WCouLk6LFi3S8uXLtW/fPk2YMEFZWVmuq6dGjBihadOmufpPmDBBP/30kx566CEdPHhQH374oZ599llNmjTJU5sAAACqGY9eCj5kyBClpqZqxowZSk5OVqdOnbRu3TrXScYnTpyQl9cv+SsyMlLr16/XlClTdN111ykiIkIPPfSQ/vrXv3pqEwAAQDVjMQzD8HQRVSk9PV3BwcFKS0vjEBUAABXo473JeuDNHbr+mhCtntijQj+7LN/fNepqKQAAgN9CuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZSLcLN3Llz1aRJE/n6+qpbt27avn17iX2XLVsmi8Xitvj6+lZhtQAAoDrzeLhJSEhQXFycZs6cqZ07d6pjx46KjY3V2bNnSxwTFBSkM2fOuJbvv/++CisGAADVmcfDzezZszV27FiNHj1abdu21YIFC+Tv768lS5aUOMZisSg8PNy1hIWFVWHFAACgOvNouMnLy9OOHTsUExPjavPy8lJMTIySkpJKHJeZmanGjRsrMjJSf/jDH7R3794S++bm5io9Pd1tAQAA5uXRcHPu3Dk5HI4ie17CwsKUnJxc7JjWrVtryZIl+s9//qN//etfcjqd6t69u3744Ydi+8fHxys4ONi1REZGVvh2AACA6sPjh6XKKjo6WiNGjFCnTp3Uq1cvrV69WvXr19fChQuL7T9t2jSlpaW5lpMnT1ZxxQAAoCp5e3Ll9erVk9VqVUpKilt7SkqKwsPDS/UZPj4+6ty5sw4fPlzs+3a7XXa7/YprBQAANYNHw43NZlNUVJQSExM1ePBgSZLT6VRiYqImT55cqs9wOBz65ptvNGDAgAqryzAMFRQUyOFwVNhnovL4+PjIarV6ugwAQDXh0XAjSXFxcRo5cqS6dOmirl27as6cOcrKytLo0aMlSSNGjFBERITi4+MlSU899ZR+97vfqUWLFjp//rxeeOEFff/99xozZkyF1JOXl6czZ84oOzu7Qj4Plc9isahRo0YKCAjwdCkAgGrA4+FmyJAhSk1N1YwZM5ScnKxOnTpp3bp1rpOMT5w4IS+vX04N+vnnnzV27FglJyerdu3aioqK0rZt29S2bdsrrsXpdOrYsWOyWq1q2LChbDabLBbLFX8uKo9hGEpNTdUPP/ygli1bsgcHACCLYRiGp4uoSunp6QoODlZaWpqCgoLc3svJydGxY8fUuHFj+fv7e6hClNWFCxd0/PhxNW3alLtVA4AHfbw3WQ+8uUPXXxOi1RN7VOhnX+77+9dq3NVSVeHSPUWo/ti7BgC4FN/iAADAVAg3AADAVAg3JpOUlCSr1aqBAwe6tR8/ftztSep169ZV3759tWvXrnKv68SJExo4cKD8/f0VGhqqRx55RAUFBZcds3PnTvXp00chISGqW7euHnjgAWVmZrreL+6p74XL5R6mCgBAIcKNySxevFj/93//p88++0ynT58u8v7GjRt15swZrV+/XpmZmerfv7/Onz9f5vU4HA4NHDhQeXl52rZtm5YvX65ly5ZpxowZJY45ffq0YmJi1KJFC3355Zdat26d9u7dq1GjRrn6DBkyxO2J72fOnFFsbKx69eql0NDQMtcJALj6EG5MJDMzUwkJCZowYYIGDhyoZcuWFelTt25dhYeHq0uXLnrxxReVkpKiL7/8sszr+vjjj/Xdd9/pX//6lzp16qT+/fvr6aef1ty5c5WXl1fsmA8++EA+Pj6aO3euWrdurRtuuEELFizQu+++67rDtJ+fn9sT361WqzZt2qT777+/zDUCAK5OhJvfYBiGsvMKPLKU9Sr9lStXqk2bNmrdurWGDx+uJUuWXPYz/Pz8JMkVRsaPH6+AgIDLLoWSkpLUoUMHt4eexsbGKj09vcSntOfm5spms7ldjVZYw5YtW4od889//lP+/v764x//WMpZAABc7Tx+E7/q7kK+Q21nrPfIur97Klb+ttL/iBYvXqzhw4dLkvr166e0tDR9+umnuvnmm4v0PX/+vJ5++mkFBASoa9euki7e/fnhhx8u1bqSk5OLfZp74XvF6d27t+Li4vTCCy/ooYceUlZWlqZOnSpJOnPmTInbNGzYMFcIAgDgtxBuTOLAgQPavn273nvvPUmSt7e3hgwZosWLF7uFm+7du8vLy0tZWVlq1qyZEhISXKEkNDS0Us9radeunZYvX664uDhNmzZNVqtVDz74oMLCwoq9t1BSUpL27dunN998s9JqAgCYD+HmN/j5WPXdU7EeW3dpLV68WAUFBWrYsKGrzTAM2e12vfbaa662hIQEtW3bVnXr1lVISIjbZ4wfP17/+te/LruewiubwsPDtX37drf3Cp/ufrknug8bNkzDhg1TSkqKatWqJYvFotmzZ6tZs2ZF+r7xxhvq1KmToqKiLlsTAACXItz8BovFUqZDQ55QUFCgf/7zn3rppZfUt29ft/cGDx6st99+W/369ZMkRUZGqnnz5sV+TlkOS0VHR+uZZ57R2bNnXXt7NmzYoKCgoFI956twb9GSJUvk6+urPn36uL2fmZmplStXuh6YCgBAaVXvb22UygcffKCff/5Z999/v4KDg93eu/POO7V48WJXuLmcshyW6tu3r9q2bav77rtPzz//vJKTkzV9+nRNmjRJdrtdkrR9+3aNGDFCiYmJioiIkCS99tpr6t69uwICArRhwwY98sgjeu6554rsRUpISFBBQYHrHCIAAEqLq6VMYPHixYqJiSkSbKSL4ebrr79Wenp6ha7TarXqgw8+kNVqVXR0tIYPH64RI0boqaeecvXJzs7WgQMHlJ+f72rbvn27+vTpow4dOuj111/XwoUL9eCDDxa7TXfccUeR0AMAqL68LBbZvb3kY/VsvOCp4JcofCo4T5euWfi5AYD58VRwAABw1SLcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcFOMqu4CsxuPnBQC4FOHmEj4+PpIu3p8FNUfhU82t1tI/rgIAYF7cofgSVqtVISEhOnv2rCTJ399fFovFw1XhcpxOp1JTU+Xv7y9vb36dAQCEmyIKH/pYGHBQ/Xl5eemaa64hiAIAJBFuirBYLGrQoIFCQ0PdHhuA6stms8nLiyOsAICLCDclsFqtnMMBAEANxD93AQCAqRBuAACAqRBuAACAqVx159wU3vAtPT3dw5UAAIDSKvzeLs2NW6+6cJORkSFJioyM9HAlAACgrDIyMhQcHHzZPhbjKrt3vdPp1OnTpxUYGFjh90VJT09XZGSkTp48qaCgoAr9bPyCea4azHPVYJ6rDnNdNSprng3DUEZGhho2bPibt/+46vbceHl5qVGjRpW6jqCgIP7DqQLMc9VgnqsG81x1mOuqURnz/Ft7bApxQjEAADAVwg0AADAVwk0Fstvtmjlzpux2u6dLMTXmuWowz1WDea46zHXVqA7zfNWdUAwAAMyNPTcAAMBUCDcAAMBUCDcAAMBUCDcAAMBUCDdlNHfuXDVp0kS+vr7q1q2btm/fftn+77zzjtq0aSNfX1916NBBa9euraJKa7ayzPOiRYvUs2dP1a5dW7Vr11ZMTMxv/lxwUVl/nwutWLFCFotFgwcPrtwCTaKs83z+/HlNmjRJDRo0kN1uV6tWrfh/RymUdZ7nzJmj1q1by8/PT5GRkZoyZYpycnKqqNqa6bPPPtOgQYPUsGFDWSwWvf/++785ZvPmzbr++utlt9vVokULLVu2rNLrlIFSW7FihWGz2YwlS5YYe/fuNcaOHWuEhIQYKSkpxfbfunWrYbVajeeff9747rvvjOnTpxs+Pj7GN998U8WV1yxlnedhw4YZc+fONXbt2mXs27fPGDVqlBEcHGz88MMPVVx5zVLWeS507NgxIyIiwujZs6fxhz/8oWqKrcHKOs+5ublGly5djAEDBhhbtmwxjh07ZmzevNnYvXt3FVdes5R1nt966y3Dbrcbb731lnHs2DFj/fr1RoMGDYwpU6ZUceU1y9q1a43HH3/cWL16tSHJeO+99y7b/+jRo4a/v78RFxdnfPfdd8arr75qWK1WY926dZVaJ+GmDLp27WpMmjTJ9drhcBgNGzY04uPji+1/9913GwMHDnRr69atmzFu3LhKrbOmK+s8/1pBQYERGBhoLF++vLJKNIXyzHNBQYHRvXt344033jBGjhxJuCmFss7z/PnzjWbNmhl5eXlVVaIplHWeJ02aZPTu3dutLS4uzujRo0el1mkmpQk3jz76qNGuXTu3tiFDhhixsbGVWJlhcFiqlPLy8rRjxw7FxMS42ry8vBQTE6OkpKRixyQlJbn1l6TY2NgS+6N88/xr2dnZys/PV506dSqrzBqvvPP81FNPKTQ0VPfff39VlFnjlWee16xZo+joaE2aNElhYWFq3769nn32WTkcjqoqu8Ypzzx3795dO3bscB26Onr0qNauXasBAwZUSc1XC099D151D84sr3PnzsnhcCgsLMytPSwsTPv37y92THJycrH9k5OTK63Omq488/xrf/3rX9WwYcMi/0HhF+WZ5y1btmjx4sXavXt3FVRoDuWZ56NHj2rTpk269957tXbtWh0+fFgTJ05Ufn6+Zs6cWRVl1zjlmedhw4bp3LlzuvHGG2UYhgoKCjR+/Hg99thjVVHyVaOk78H09HRduHBBfn5+lbJe9tzAVJ577jmtWLFC7733nnx9fT1djmlkZGTovvvu06JFi1SvXj1Pl2NqTqdToaGhev311xUVFaUhQ4bo8ccf14IFCzxdmqls3rxZzz77rObNm6edO3dq9erV+vDDD/X00097ujRUAPbclFK9evVktVqVkpLi1p6SkqLw8PBix4SHh5epP8o3z4VefPFFPffcc9q4caOuu+66yiyzxivrPB85ckTHjx/XoEGDXG1Op1OS5O3trQMHDqh58+aVW3QNVJ7f5wYNGsjHx0dWq9XVdu211yo5OVl5eXmy2WyVWnNNVJ55fuKJJ3TfffdpzJgxkqQOHTooKytLDzzwgB5//HF5efFv/4pQ0vdgUFBQpe21kdhzU2o2m01RUVFKTEx0tTmdTiUmJio6OrrYMdHR0W79JWnDhg0l9kf55lmSnn/+eT399NNat26dunTpUhWl1mhlnec2bdrom2++0e7du13L73//e91yyy3avXu3IiMjq7L8GqM8v889evTQ4cOHXeFRkg4ePKgGDRoQbEpQnnnOzs4uEmAKA6XBIxcrjMe+Byv1dGWTWbFihWG3241ly5YZ3333nfHAAw8YISEhRnJysmEYhnHfffcZU6dOdfXfunWr4e3tbbz44ovGvn37jJkzZ3IpeCmUdZ6fe+45w2azGatWrTLOnDnjWjIyMjy1CTVCWef517haqnTKOs8nTpwwAgMDjcmTJxsHDhwwPvjgAyM0NNT4+9//7qlNqBHKOs8zZ840AgMDjbfffts4evSo8fHHHxvNmzc37r77bk9tQo2QkZFh7Nq1y9i1a5chyZg9e7axa9cu4/vvvzcMwzCmTp1q3Hfffa7+hZeCP/LII8a+ffuMuXPncil4dfTqq68a11xzjWGz2YyuXbsaX3zxheu9Xr16GSNHjnTrv3LlSqNVq1aGzWYz2rVrZ3z44YdVXHHNVJZ5bty4sSGpyDJz5syqL7yGKevv86UIN6VX1nnetm2b0a1bN8NutxvNmjUznnnmGaOgoKCKq655yjLP+fn5xt/+9jejefPmhq+vrxEZGWlMnDjR+Pnnn6u+8Brkk08+Kfb/t4VzO3LkSKNXr15FxnTq1Mmw2WxGs2bNjKVLl1Z6nRbDYP8bAAAwD865AQAApkK4AQAApkK4AQAApkK4AQAApkK4AQAApkK4AQAApkK4AQAApkK4AQBJFotF77//viTp+PHjslgsPAEdqKEINwA8btSoUbJYLLJYLPLx8VHTpk316KOPKicnx9OlAaiBeCo4gGqhX79+Wrp0qfLz87Vjxw6NHDlSFotFs2bN8nRpAGoY9twAqBbsdrvCw8MVGRmpwYMHKyYmRhs2bJB08QnP8fHxatq0qfz8/NSxY0etWrXKbfzevXt12223KSgoSIGBgerZs6eOHDkiSfrqq6/Up08f1atXT8HBwerVq5d27txZ5dsIoGoQbgBUO99++622bdsmm80mSYqPj9c///lPLViwQHv37tWUKVM0fPhwffrpp5KkU6dO6aabbpLdbtemTZu0Y8cO/elPf1JBQYEkKSMjQyNHjtSWLVv0xRdfqGXLlhowYIAyMjI8to0AKg+HpQBUCx988IECAgJUUFCg3NxceXl56bXXXlNubq6effZZbdy4UdHR0ZKkZs2aacuWLVq4cKF69eqluXPnKjg4WCtWrJCPj48kqVWrVq7P7t27t9u6Xn/9dYWEhOjTTz/VbbfdVnUbCaBKEG4AVAu33HKL5s+fr6ysLL388svy9vbWnXfeqb179yo7O1t9+vRx65+Xl6fOnTtLknbv3q2ePXu6gs2vpaSkaPr06dq8ebPOnj0rh8Oh7OxsnThxotK3C0DVI9wAqBZq1aqlFi1aSJKWLFmijh07avHixWrfvr0k6cMPP1RERITbGLvdLkny8/O77GePHDlSP/74o1555RU1btxYdrtd0dHRysvLq4QtAeBphBsA1Y6Xl5cee+wxxcXF6eDBg7Lb7Tpx4oR69epVbP/rrrtOy5cvV35+frF7b7Zu3ap58+ZpwIABkqSTJ0/q3LlzlboNADyHE4oBVEt33XWXrFarFi5cqIcfflhTpkzR8uXLdeTIEe3cuVOvvvqqli9fLkmaPHmy0tPTdc899+jrr7/WoUOH9Oabb+rAgQOSpJYtW+rNN9/Uvn379OWXX+ree+/9zb09AGou9twAqJa8vb01efJkPf/88zp27Jjq16+v+Ph4HT16VCEhIbr++uv12GOPSZLq1q2rTZs26ZFHHlGvXr1ktVrVqVMn9ejRQ5K0ePFiPfDAA7r++usVGRmpZ599Vg8//LAnNw9AJbIYhmF4uggAAICKwmEpAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKv8fHBFqToGemNoAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#44. Train a Stacking Classifier with Random Forest and Logistic Regression and compare accuracy.\n",
        "\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "# Generate a sample dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=42)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define base estimators\n",
        "estimators = [\n",
        "    ('rf', RandomForestClassifier(random_state=42)),\n",
        "    ('lr', LogisticRegression(random_state=42))\n",
        "]\n",
        "\n",
        "# Define the stacking classifier\n",
        "stacking_clf = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression(random_state=42))\n",
        "\n",
        "# Train the stacking classifier\n",
        "stacking_clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_stacking = stacking_clf.predict(X_test)\n",
        "\n",
        "# Evaluate the stacking classifier's accuracy\n",
        "stacking_accuracy = accuracy_score(y_test, y_pred_stacking)\n",
        "print(f\"Stacking Classifier Accuracy: {stacking_accuracy}\")\n",
        "\n",
        "# Train individual classifiers for comparison\n",
        "for name, estimator in estimators:\n",
        "    estimator.fit(X_train, y_train)\n",
        "    y_pred = estimator.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"{name} Accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJjNIZP-tFED",
        "outputId": "8a0e2cd8-9f71-4295-9ac0-5faf86d72790"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacking Classifier Accuracy: 0.87\n",
            "rf Accuracy: 0.9\n",
            "lr Accuracy: 0.825\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#45. Train a Bagging Regressor with different levels of bootstrap samples and compare performance.\n",
        "\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Generate a sample regression dataset\n",
        "X, y = make_regression(n_samples=1000, n_features=20, n_informative=15, noise=0.1, random_state=42)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Bootstrap sample ratios to try\n",
        "bootstrap_ratios = [0.1, 0.5, 0.8, 1.0]\n",
        "\n",
        "for ratio in bootstrap_ratios:\n",
        "    # Create a Bagging Regressor\n",
        "    bagging_reg = BaggingRegressor(DecisionTreeRegressor(), n_estimators=100, max_samples=ratio, random_state=42)\n",
        "\n",
        "    # Train the model\n",
        "    bagging_reg.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = bagging_reg.predict(X_test)\n",
        "\n",
        "    # Evaluate the model using Mean Squared Error\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    print(f\"Mean Squared Error with max_samples={ratio}: {mse}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c56XR9-tM6Z",
        "outputId": "35c08098-49df-432c-eddb-9128799290a0"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error with max_samples=0.1: 21577.926756876186\n",
            "Mean Squared Error with max_samples=0.5: 16947.83061048976\n",
            "Mean Squared Error with max_samples=0.8: 15740.122881251778\n",
            "Mean Squared Error with max_samples=1.0: 15815.26660224182\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IqjySVhatXm6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}